{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c018537b-f962-4375-aae6-df4536a2311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example: load 2023 season play-by-play\n",
    "\n",
    "def show_columns(filename): \n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    # https://github.com/nflverse/nflverse-data/releases/tag/pbp\n",
    "    \n",
    "    print(df.columns)\n",
    "    df.head()\n",
    "    \n",
    "    for column_name in df:\n",
    "        print(f\"{column_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ef96600-c6f8-4596-8ec0-15235b1f2e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "def load_data(filename): \n",
    "    \n",
    "    DB_CONFIG = {\n",
    "        \"dbname\": \"nfl_historical\",\n",
    "        \"user\": \"postgres\",\n",
    "        \"password\": \"postgres\",\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": 5432,\n",
    "    }\n",
    "    \n",
    "    # === READ CSV ===\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    # === CONNECT TO DATABASE ===\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    \n",
    "    # === CREATE TABLES IF NOT EXIST ===\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS games (\n",
    "        id TEXT PRIMARY KEY,\n",
    "        home_team TEXT NOT NULL,\n",
    "        away_team TEXT NOT NULL,\n",
    "        description TEXT NOT NULL,\n",
    "        game_date date NOT NULL,\n",
    "        season_type TEXT NOT NULL,\n",
    "        week smallint NOT NULL\n",
    "    );\n",
    "    \"\"\")\n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS plays (\n",
    "        id TEXT PRIMARY KEY,\n",
    "        game_id TEXT NOT NULL REFERENCES games(id) ON DELETE CASCADE,\n",
    "        posteam TEXT NOT NULL,\n",
    "        posteam_type TEXT NOT NULL,\n",
    "        defteam TEXT NOT NULL,\n",
    "        total_home_score int,\n",
    "        total_away_score int,\n",
    "        qtr smallint,\n",
    "        quarter_seconds_remaining float,\n",
    "        game_seconds_remaining float\n",
    "    );\n",
    "    \"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "    \n",
    "    # === INSERT INTO games ===\n",
    "    # Use UPSERT to avoid duplicates (in case same game appears multiple times)\n",
    "    games = df[[\"game_id\", \"home_team\", \"away_team\", \"desc\", \"game_date\", \"season_type\", \"week\", ]].drop_duplicates(subset=[\"game_id\"])\n",
    "    \n",
    "    execute_values(\n",
    "        cur,\n",
    "        \"\"\"\n",
    "        INSERT INTO games (id, home_team, away_team, description, game_date, season_type, week)\n",
    "        VALUES %s\n",
    "        ON CONFLICT (id) DO UPDATE SET \n",
    "          home_team = EXCLUDED.home_team,\n",
    "          away_team = EXCLUDED.away_team,\n",
    "          game_date = EXCLUDED.game_date,\n",
    "          season_type = EXCLUDED.season_type,\n",
    "          week = EXCLUDED.week\n",
    "        \"\"\",\n",
    "        list(games.itertuples(index=False, name=None))\n",
    "    )\n",
    "    \n",
    "    # === INSERT INTO plays ===\n",
    "    plays = df[[\"play_id\", \"game_id\", \"posteam\", \"posteam_type\", \"defteam\", \"total_home_score\", \"total_away_score\", \"qtr\", \"quarter_seconds_remaining\", \"game_seconds_remaining\"]].drop_duplicates(subset=[\"play_id\"])\n",
    "    \n",
    "    plays[\"play_id\"] = plays[\"game_id\"].astype(str) + \"_\" + plays[\"play_id\"].astype(str)\n",
    "    \n",
    "    execute_values(\n",
    "        cur,\n",
    "        \"\"\"\n",
    "        INSERT INTO plays (\n",
    "            id, \n",
    "            game_id, \n",
    "            posteam, \n",
    "            posteam_type, \n",
    "            defteam,\n",
    "            total_home_score, \n",
    "            total_away_score, \n",
    "            qtr,\n",
    "            quarter_seconds_remaining,\n",
    "            game_seconds_remaining\n",
    "        )\n",
    "        VALUES %s\n",
    "        ON CONFLICT (id) DO UPDATE SET\n",
    "          game_id = EXCLUDED.game_id,\n",
    "          posteam = EXCLUDED.posteam,\n",
    "          posteam_type = EXCLUDED.posteam_type,\n",
    "          defteam = EXCLUDED.defteam,\n",
    "          total_home_score = EXCLUDED.total_home_score,\n",
    "          total_away_score = EXCLUDED.total_away_score,\n",
    "          qtr = EXCLUDED.qtr,\n",
    "          quarter_seconds_remaining = EXCLUDED.game_seconds_remaining,\n",
    "          game_seconds_remaining = EXCLUDED.game_seconds_remaining\n",
    "        \"\"\",\n",
    "        list(plays.itertuples(index=False, name=None))\n",
    "    )\n",
    "    \n",
    "    # === COMMIT AND CLEANUP ===\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    print(\"Data import completed successfully.\")\n",
    "    print(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a17e5ac8-c5dd-4c0b-ab67-0f3ae5052d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#show_columns(\"./play_by_play_2006.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d0d7a7a-34c3-46b6-9eeb-6d3a193b4e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47431/3253985518.py:16: DtypeWarning: Columns (45,179,180,182,183,189,190,193,194,197,198,203,204,205,206,213,214,218,219,220,248,249,253,254,255,260,262,263,266,267,268,269,283,284) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data import completed successfully.\n",
      "../../data/nfl/play_by_play_2012.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47431/3253985518.py:16: DtypeWarning: Columns (179,180,182,183,193,194,197,198,203,204,205,206,209,210,218,219,220,253,254,255,260,262,263,283,284) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data import completed successfully.\n",
      "../../data/nfl/play_by_play_2013.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47431/3253985518.py:16: DtypeWarning: Columns (45,179,180,182,183,189,190,193,194,197,198,203,204,205,206,218,219,220,248,249,253,254,255,260,262,263,283,284) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data import completed successfully.\n",
      "../../data/nfl/play_by_play_2014.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47431/3253985518.py:16: DtypeWarning: Columns (45,179,180,182,183,189,190,193,194,197,198,203,204,205,206,218,219,220,233,234,235,236,237,238,248,249,253,254,255,260,262,263,283,284) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data import completed successfully.\n",
      "../../data/nfl/play_by_play_2015.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47431/3253985518.py:16: DtypeWarning: Columns (179,180,182,183,189,190,193,194,197,198,203,204,205,206,209,210,218,219,220,248,249,253,254,255,260,262,263,283,284) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data import completed successfully.\n",
      "../../data/nfl/play_by_play_2016.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47431/3253985518.py:16: DtypeWarning: Columns (179,180,182,183,189,190,191,192,193,194,197,198,199,200,203,204,205,206,213,214,218,219,220,248,249,253,254,255,260,262,263,266,267,268,269,283,284) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data import completed successfully.\n",
      "../../data/nfl/play_by_play_2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47431/3253985518.py:16: DtypeWarning: Columns (40,41,44,45,49,50,51,52,179,180,182,183,187,188,191,192,193,194,195,196,197,198,199,200,203,204,205,206,207,208,211,212,213,214,215,216,217,218,219,220,222,224,226,227,228,229,230,231,232,240,241,242,246,247,248,249,250,251,252,253,254,255,256,258,259,260,262,263,264,265,266,267,268,269,270,272,273,274,277,278,283,284) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data import completed successfully.\n",
      "../../data/nfl/play_by_play_2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47431/3253985518.py:16: DtypeWarning: Columns (45,179,180,182,183,189,190,193,194,197,198,203,204,205,206,209,210,218,219,220,233,234,235,236,237,238,248,249,253,254,255,260,262,263,283,284,302) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data import completed successfully.\n",
      "../../data/nfl/play_by_play_2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47431/3253985518.py:16: DtypeWarning: Columns (45,179,180,182,183,187,188,189,190,193,194,197,198,203,204,205,206,213,214,218,219,220,222,224,226,243,244,245,248,249,253,254,255,260,262,263,266,267,268,269,283,284) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data import completed successfully.\n",
      "../../data/nfl/play_by_play_2022.csv\n"
     ]
    }
   ],
   "source": [
    "#load_data(\"./play_by_play_2006.csv\")\n",
    "#load_data(\"./play_by_play_2020.csv\")\n",
    "#load_data(\"./play_by_play_2021.csv\")\n",
    "load_data(\"../../data/nfl/play_by_play_2012.csv\")\n",
    "load_data(\"../../data/nfl/play_by_play_2013.csv\")\n",
    "load_data(\"../../data/nfl/play_by_play_2014.csv\")\n",
    "load_data(\"../../data/nfl/play_by_play_2015.csv\")\n",
    "load_data(\"../../data/nfl/play_by_play_2016.csv\")\n",
    "load_data(\"../../data/nfl/play_by_play_2017.csv\")\n",
    "load_data(\"../../data/nfl/play_by_play_2018.csv\")\n",
    "load_data(\"../../data/nfl/play_by_play_2019.csv\")\n",
    "load_data(\"../../data/nfl/play_by_play_2022.csv\")\n",
    "#load_data(\"./play_by_play_2023.csv\")\n",
    "#load_data(\"./play_by_play_2024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fdd48d3-098e-486c-a500-4284606b7869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "\n",
    "def calculate_probabilities(): \n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",        # or your host name\n",
    "        port=\"5432\",             # default Postgres port\n",
    "        dbname=\"nfl_historical\",  # change this\n",
    "        user=\"postgres\",        # change this\n",
    "        password=\"postgres\" # change this\n",
    "    )\n",
    "    \n",
    "    games = pd.read_sql(\"SELECT * FROM games;\", conn)\n",
    "    plays = pd.read_sql(\"SELECT * FROM plays;\", conn)\n",
    "    \n",
    "    print(\"Games:\", games.shape)\n",
    "    print(\"Plays:\", plays.shape)\n",
    "    print(games.head())\n",
    "    print(plays.head())\n",
    "    \n",
    "    conn.close()\n",
    "\n",
    "    #Add outcome (did home team win?) to each game ---\n",
    "    games[\"home_win\"] = (games[\"total_home_score\"] > games[\"total_away_score\"]).astype(int)\n",
    "    \n",
    "    #Merge plays with their game's win outcome ---\n",
    "    df = plays.merge(games[[\"id\", \"home_win\"]], left_on=\"game_id\", right_on=\"id\", how=\"inner\")\n",
    "    \n",
    "    #Filter for 4th quarter only ---\n",
    "    df = df[df[\"qtr\"] == 4].copy()\n",
    "    \n",
    "    #Compute score differential (home - away) ---\n",
    "    df[\"diff\"] = df[\"total_home_score\"] - df[\"total_away_score\"]\n",
    "    \n",
    "    #Define time buckets (seconds remaining) ---\n",
    "    def time_bucket(sec_left):\n",
    "        if 60 <= sec_left < 120:\n",
    "            return \"1-2 min\"\n",
    "        elif 120 <= sec_left < 180:\n",
    "            return \"2-3 min\"\n",
    "        elif 180 <= sec_left < 240:\n",
    "            return \"3-4 min\"\n",
    "        elif 240 <= sec_left < 300:\n",
    "            return \"4-5 min\"\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    df[\"time_bucket\"] = df[\"game_seconds_remaining\"].apply(time_bucket)\n",
    "    \n",
    "    #Define score buckets ---\n",
    "    def score_bucket(diff):\n",
    "        if diff == 3:\n",
    "            return \"ahead by 3\"\n",
    "        elif diff == 4:\n",
    "            return \"ahead by 4\"\n",
    "        elif diff == 5:\n",
    "            return \"ahead by 5\"\n",
    "        elif diff == 6:\n",
    "            return \"ahead by 6\"\n",
    "        elif diff == 7:\n",
    "            return \"ahead by 7\"\n",
    "        elif diff > 7:\n",
    "            return \"ahead by >7\"\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    df[\"score_bucket\"] = df[\"diff\"].apply(score_bucket)\n",
    "    \n",
    "    #Filter only cases where home team is leading (diff >= 3) and valid buckets ---\n",
    "    df = df[(df[\"diff\"] >= 3) & df[\"time_bucket\"].notna() & df[\"score_bucket\"].notna()]\n",
    "    \n",
    "    #Aggregate: compute empirical probability ---\n",
    "    result = (\n",
    "        df.groupby([\"time_bucket\", \"score_bucket\"])\n",
    "          .agg(\n",
    "              situations=(\"game_id\", \"count\"),\n",
    "              prob_home_win=(\"home_win\", \"mean\")\n",
    "          )\n",
    "          .reset_index()\n",
    "          .sort_values([\"time_bucket\", \"score_bucket\"])\n",
    "    )\n",
    "    \n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ae39ef6-5c0e-44a2-a87a-214830618a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47431/2765686778.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  games = pd.read_sql(\"SELECT * FROM games;\", conn)\n",
      "/tmp/ipykernel_47431/2765686778.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  plays = pd.read_sql(\"SELECT * FROM plays;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games: (3811, 7)\n",
      "Plays: (22600, 10)\n",
      "                id home_team away_team description   game_date season_type  \\\n",
      "0  2023_01_ARI_WAS       WAS       ARI        GAME  2023-09-10         REG   \n",
      "1  2023_01_BUF_NYJ       NYJ       BUF        GAME  2023-09-11         REG   \n",
      "2  2023_01_CAR_ATL       ATL       CAR        GAME  2023-09-10         REG   \n",
      "3  2023_01_CIN_CLE       CLE       CIN        GAME  2023-09-10         REG   \n",
      "4  2023_01_DAL_NYG       NYG       DAL        GAME  2023-09-10         REG   \n",
      "\n",
      "   week  \n",
      "0     1  \n",
      "1     1  \n",
      "2     1  \n",
      "3     1  \n",
      "4     1  \n",
      "                    id         game_id posteam posteam_type defteam  \\\n",
      "0  2012_01_ATL_KC_2619  2012_01_ATL_KC     ATL         away      KC   \n",
      "1  2012_01_ATL_KC_2643  2012_01_ATL_KC     ATL         away      KC   \n",
      "2  2012_01_ATL_KC_2665  2012_01_ATL_KC     ATL         away      KC   \n",
      "3  2012_01_ATL_KC_2684  2012_01_ATL_KC      KC         home     ATL   \n",
      "4  2012_01_ATL_KC_2706  2012_01_ATL_KC      KC         home     ATL   \n",
      "\n",
      "   total_home_score  total_away_score  qtr  quarter_seconds_remaining  \\\n",
      "0                17                34    4                      900.0   \n",
      "1                17                34    4                      861.0   \n",
      "2                17                37    4                      856.0   \n",
      "3                17                37    4                      853.0   \n",
      "4                17                37    4                      846.0   \n",
      "\n",
      "   game_seconds_remaining  \n",
      "0                   900.0  \n",
      "1                   861.0  \n",
      "2                   856.0  \n",
      "3                   853.0  \n",
      "4                   846.0  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'total_home_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/development/prediction-markets/python/lib/python3.12/site-packages/pandas/core/indexes/base.py:3802\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key, method, tolerance)\u001b[39m\n\u001b[32m   3801\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3802\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3803\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/development/prediction-markets/python/lib/python3.12/site-packages/pandas/_libs/index.pyx:138\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/development/prediction-markets/python/lib/python3.12/site-packages/pandas/_libs/index.pyx:165\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'total_home_score'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcalculate_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mcalculate_probabilities\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     22\u001b[39m conn.close()\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m#Add outcome (did home team win?) to each game ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m games[\u001b[33m\"\u001b[39m\u001b[33mhome_win\u001b[39m\u001b[33m\"\u001b[39m] = (\u001b[43mgames\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtotal_home_score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m > games[\u001b[33m\"\u001b[39m\u001b[33mtotal_away_score\u001b[39m\u001b[33m\"\u001b[39m]).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m#Merge plays with their game's win outcome ---\u001b[39;00m\n\u001b[32m     28\u001b[39m df = plays.merge(games[[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhome_win\u001b[39m\u001b[33m\"\u001b[39m]], left_on=\u001b[33m\"\u001b[39m\u001b[33mgame_id\u001b[39m\u001b[33m\"\u001b[39m, right_on=\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m, how=\u001b[33m\"\u001b[39m\u001b[33minner\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/development/prediction-markets/python/lib/python3.12/site-packages/pandas/core/frame.py:3807\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3805\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   3806\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m3807\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3808\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   3809\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/development/prediction-markets/python/lib/python3.12/site-packages/pandas/core/indexes/base.py:3804\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key, method, tolerance)\u001b[39m\n\u001b[32m   3802\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._engine.get_loc(casted_key)\n\u001b[32m   3803\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m-> \u001b[39m\u001b[32m3804\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3805\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3806\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3808\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3809\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'total_home_score'"
     ]
    }
   ],
   "source": [
    "calculate_probabilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b960d7-ad8f-435c-b624-823f770ed11d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
